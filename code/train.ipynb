{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db91987d",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab699287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd93a84d",
   "metadata": {},
   "source": [
    "### Read the dataset of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e977bc15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>CreditLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15762418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.484985</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.643290</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15749905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.251062</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15600911</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.728934</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.015250</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15572762</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.407651</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.449146</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15627848</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.435819</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.513377</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CustomerId  France  Germany  Spain  Tenure   Balance  NumOfProducts  \\\n",
       "0    15762418     0.0      0.0    1.0     0.3  0.484985       0.000000   \n",
       "1    15749905     0.0      0.0    1.0     0.6  0.000000       0.000000   \n",
       "2    15600911     1.0      0.0    0.0     0.2  0.728934       0.000000   \n",
       "3    15572762     0.0      1.0    0.0     0.2  0.407651       0.333333   \n",
       "4    15627848     1.0      0.0    0.0     0.7  0.435819       0.333333   \n",
       "\n",
       "   HasCrCard  IsActiveMember  EstimatedSalary  Exited  CreditLevel  \n",
       "0          1               0         0.643290       1            7  \n",
       "1          1               0         0.251062       1            6  \n",
       "2          1               0         0.015250       0            6  \n",
       "3          1               0         0.449146       0            1  \n",
       "4          1               0         0.513377       0            6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('BankChurners_preprocess.csv')\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0004f6b8",
   "metadata": {},
   "source": [
    "#### Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3fe6ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df_train, test_size=0.2, random_state = 1)\n",
    "\n",
    "train_y = pd.DataFrame(train['CreditLevel'])\n",
    "train_X = train.drop(columns=['CreditLevel'])\n",
    "train_X = train_X.drop(columns=['CustomerId'])\n",
    "\n",
    "test_y = pd.DataFrame(test['CreditLevel'])\n",
    "test_X = test.drop(columns=['CreditLevel'])\n",
    "test_X = test_X.drop(columns=['CustomerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f19172d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(torch.Tensor(np.array(train_X)), torch.squeeze(torch.Tensor(np.array(train_y))))\n",
    "test_set = torch.utils.data.TensorDataset(torch.Tensor(np.array(test_X)), torch.squeeze(torch.Tensor(np.array(test_y))))\n",
    "            \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=64, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=64, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cd5797",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "234ee0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.01)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.01)\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7a7b8b7",
   "metadata": {},
   "source": [
    "#### Loss function and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10892ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e50a72c",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17919c9c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817/3075316110.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels,dtype = torch.long)\n",
      "/tmp/ipykernel_817/2053517580.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [50/113], Loss: 2.2434 Validation Accuracy: 21.5 %\n",
      "Epoch [1/50], Step [100/113], Loss: 2.2225 Validation Accuracy: 21.555555555555557 %\n",
      "Epoch [2/50], Step [50/113], Loss: 2.1610 Validation Accuracy: 21.38888888888889 %\n",
      "Epoch [2/50], Step [100/113], Loss: 2.1951 Validation Accuracy: 20.555555555555557 %\n",
      "Epoch [3/50], Step [50/113], Loss: 2.2080 Validation Accuracy: 21.333333333333332 %\n",
      "Epoch [3/50], Step [100/113], Loss: 2.2036 Validation Accuracy: 21.0 %\n",
      "Epoch [4/50], Step [50/113], Loss: 2.2296 Validation Accuracy: 21.666666666666668 %\n",
      "Epoch [4/50], Step [100/113], Loss: 2.1761 Validation Accuracy: 21.22222222222222 %\n",
      "Epoch [5/50], Step [50/113], Loss: 2.1840 Validation Accuracy: 20.333333333333332 %\n",
      "Epoch [5/50], Step [100/113], Loss: 2.2327 Validation Accuracy: 21.38888888888889 %\n",
      "Epoch [6/50], Step [50/113], Loss: 2.3232 Validation Accuracy: 20.5 %\n",
      "Epoch [6/50], Step [100/113], Loss: 2.2178 Validation Accuracy: 22.055555555555557 %\n",
      "Epoch [7/50], Step [50/113], Loss: 2.2556 Validation Accuracy: 21.38888888888889 %\n",
      "Epoch [7/50], Step [100/113], Loss: 2.1645 Validation Accuracy: 21.055555555555557 %\n",
      "Epoch [8/50], Step [50/113], Loss: 2.1766 Validation Accuracy: 21.22222222222222 %\n",
      "Epoch [8/50], Step [100/113], Loss: 2.2249 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [9/50], Step [50/113], Loss: 2.2011 Validation Accuracy: 22.11111111111111 %\n",
      "Epoch [9/50], Step [100/113], Loss: 2.2219 Validation Accuracy: 20.166666666666668 %\n",
      "Epoch [10/50], Step [50/113], Loss: 2.2384 Validation Accuracy: 20.944444444444443 %\n",
      "Epoch [10/50], Step [100/113], Loss: 2.1574 Validation Accuracy: 21.5 %\n",
      "Epoch [11/50], Step [50/113], Loss: 2.2720 Validation Accuracy: 20.5 %\n",
      "Epoch [11/50], Step [100/113], Loss: 2.2076 Validation Accuracy: 21.833333333333332 %\n",
      "Epoch [12/50], Step [50/113], Loss: 2.2215 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [12/50], Step [100/113], Loss: 2.1591 Validation Accuracy: 21.833333333333332 %\n",
      "Epoch [13/50], Step [50/113], Loss: 2.1871 Validation Accuracy: 20.72222222222222 %\n",
      "Epoch [13/50], Step [100/113], Loss: 2.1791 Validation Accuracy: 21.5 %\n",
      "Epoch [14/50], Step [50/113], Loss: 2.1678 Validation Accuracy: 21.333333333333332 %\n",
      "Epoch [14/50], Step [100/113], Loss: 2.2134 Validation Accuracy: 21.055555555555557 %\n",
      "Epoch [15/50], Step [50/113], Loss: 2.2181 Validation Accuracy: 19.88888888888889 %\n",
      "Epoch [15/50], Step [100/113], Loss: 2.2946 Validation Accuracy: 20.72222222222222 %\n",
      "Epoch [16/50], Step [50/113], Loss: 2.1835 Validation Accuracy: 20.333333333333332 %\n",
      "Epoch [16/50], Step [100/113], Loss: 2.2207 Validation Accuracy: 21.11111111111111 %\n",
      "Epoch [17/50], Step [50/113], Loss: 2.2276 Validation Accuracy: 21.666666666666668 %\n",
      "Epoch [17/50], Step [100/113], Loss: 2.1796 Validation Accuracy: 21.38888888888889 %\n",
      "Epoch [18/50], Step [50/113], Loss: 2.1981 Validation Accuracy: 20.333333333333332 %\n",
      "Epoch [18/50], Step [100/113], Loss: 2.2075 Validation Accuracy: 21.11111111111111 %\n",
      "Epoch [19/50], Step [50/113], Loss: 2.2499 Validation Accuracy: 20.666666666666668 %\n",
      "Epoch [19/50], Step [100/113], Loss: 2.1785 Validation Accuracy: 20.666666666666668 %\n",
      "Epoch [20/50], Step [50/113], Loss: 2.1721 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [20/50], Step [100/113], Loss: 2.2240 Validation Accuracy: 21.38888888888889 %\n",
      "Epoch [21/50], Step [50/113], Loss: 2.1832 Validation Accuracy: 20.61111111111111 %\n",
      "Epoch [21/50], Step [100/113], Loss: 2.2158 Validation Accuracy: 21.5 %\n",
      "Epoch [22/50], Step [50/113], Loss: 2.2064 Validation Accuracy: 21.27777777777778 %\n",
      "Epoch [22/50], Step [100/113], Loss: 2.2157 Validation Accuracy: 21.333333333333332 %\n",
      "Epoch [23/50], Step [50/113], Loss: 2.2171 Validation Accuracy: 20.77777777777778 %\n",
      "Epoch [23/50], Step [100/113], Loss: 2.2379 Validation Accuracy: 20.833333333333332 %\n",
      "Epoch [24/50], Step [50/113], Loss: 2.2220 Validation Accuracy: 21.555555555555557 %\n",
      "Epoch [24/50], Step [100/113], Loss: 2.2158 Validation Accuracy: 20.77777777777778 %\n",
      "Epoch [25/50], Step [50/113], Loss: 2.1749 Validation Accuracy: 20.555555555555557 %\n",
      "Epoch [25/50], Step [100/113], Loss: 2.1749 Validation Accuracy: 21.333333333333332 %\n",
      "Epoch [26/50], Step [50/113], Loss: 2.2441 Validation Accuracy: 21.11111111111111 %\n",
      "Epoch [26/50], Step [100/113], Loss: 2.2127 Validation Accuracy: 21.333333333333332 %\n",
      "Epoch [27/50], Step [50/113], Loss: 2.2110 Validation Accuracy: 20.61111111111111 %\n",
      "Epoch [27/50], Step [100/113], Loss: 2.1674 Validation Accuracy: 21.0 %\n",
      "Epoch [28/50], Step [50/113], Loss: 2.2407 Validation Accuracy: 20.38888888888889 %\n",
      "Epoch [28/50], Step [100/113], Loss: 2.2511 Validation Accuracy: 21.0 %\n",
      "Epoch [29/50], Step [50/113], Loss: 2.2245 Validation Accuracy: 20.77777777777778 %\n",
      "Epoch [29/50], Step [100/113], Loss: 2.1485 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [30/50], Step [50/113], Loss: 2.2331 Validation Accuracy: 21.22222222222222 %\n",
      "Epoch [30/50], Step [100/113], Loss: 2.1809 Validation Accuracy: 21.055555555555557 %\n",
      "Epoch [31/50], Step [50/113], Loss: 2.2351 Validation Accuracy: 21.166666666666668 %\n",
      "Epoch [31/50], Step [100/113], Loss: 2.2113 Validation Accuracy: 20.444444444444443 %\n",
      "Epoch [32/50], Step [50/113], Loss: 2.2136 Validation Accuracy: 20.944444444444443 %\n",
      "Epoch [32/50], Step [100/113], Loss: 2.2248 Validation Accuracy: 20.27777777777778 %\n",
      "Epoch [33/50], Step [50/113], Loss: 2.2101 Validation Accuracy: 21.22222222222222 %\n",
      "Epoch [33/50], Step [100/113], Loss: 2.1904 Validation Accuracy: 20.22222222222222 %\n",
      "Epoch [34/50], Step [50/113], Loss: 2.2334 Validation Accuracy: 20.444444444444443 %\n",
      "Epoch [34/50], Step [100/113], Loss: 2.2188 Validation Accuracy: 21.27777777777778 %\n",
      "Epoch [35/50], Step [50/113], Loss: 2.1982 Validation Accuracy: 20.944444444444443 %\n",
      "Epoch [35/50], Step [100/113], Loss: 2.2331 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [36/50], Step [50/113], Loss: 2.1972 Validation Accuracy: 20.61111111111111 %\n",
      "Epoch [36/50], Step [100/113], Loss: 2.2204 Validation Accuracy: 20.555555555555557 %\n",
      "Epoch [37/50], Step [50/113], Loss: 2.2379 Validation Accuracy: 20.5 %\n",
      "Epoch [37/50], Step [100/113], Loss: 2.2011 Validation Accuracy: 20.77777777777778 %\n",
      "Epoch [38/50], Step [50/113], Loss: 2.2121 Validation Accuracy: 21.166666666666668 %\n",
      "Epoch [38/50], Step [100/113], Loss: 2.2015 Validation Accuracy: 19.944444444444443 %\n",
      "Epoch [39/50], Step [50/113], Loss: 2.2547 Validation Accuracy: 20.666666666666668 %\n",
      "Epoch [39/50], Step [100/113], Loss: 2.2260 Validation Accuracy: 20.27777777777778 %\n",
      "Epoch [40/50], Step [50/113], Loss: 2.2356 Validation Accuracy: 21.055555555555557 %\n",
      "Epoch [40/50], Step [100/113], Loss: 2.2302 Validation Accuracy: 21.333333333333332 %\n",
      "Epoch [41/50], Step [50/113], Loss: 2.2183 Validation Accuracy: 20.61111111111111 %\n",
      "Epoch [41/50], Step [100/113], Loss: 2.1948 Validation Accuracy: 20.72222222222222 %\n",
      "Epoch [42/50], Step [50/113], Loss: 2.2219 Validation Accuracy: 20.833333333333332 %\n",
      "Epoch [42/50], Step [100/113], Loss: 2.2197 Validation Accuracy: 20.72222222222222 %\n",
      "Epoch [43/50], Step [50/113], Loss: 2.2050 Validation Accuracy: 21.0 %\n",
      "Epoch [43/50], Step [100/113], Loss: 2.2301 Validation Accuracy: 20.11111111111111 %\n",
      "Epoch [44/50], Step [50/113], Loss: 2.2313 Validation Accuracy: 20.61111111111111 %\n",
      "Epoch [44/50], Step [100/113], Loss: 2.1890 Validation Accuracy: 20.666666666666668 %\n",
      "Epoch [45/50], Step [50/113], Loss: 2.1905 Validation Accuracy: 20.555555555555557 %\n",
      "Epoch [45/50], Step [100/113], Loss: 2.1654 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [46/50], Step [50/113], Loss: 2.2749 Validation Accuracy: 20.666666666666668 %\n",
      "Epoch [46/50], Step [100/113], Loss: 2.1985 Validation Accuracy: 20.88888888888889 %\n",
      "Epoch [47/50], Step [50/113], Loss: 2.2296 Validation Accuracy: 20.5 %\n",
      "Epoch [47/50], Step [100/113], Loss: 2.2012 Validation Accuracy: 20.833333333333332 %\n",
      "Epoch [48/50], Step [50/113], Loss: 2.2121 Validation Accuracy: 20.61111111111111 %\n",
      "Epoch [48/50], Step [100/113], Loss: 2.1574 Validation Accuracy: 20.666666666666668 %\n",
      "Epoch [49/50], Step [50/113], Loss: 2.2095 Validation Accuracy: 20.38888888888889 %\n",
      "Epoch [49/50], Step [100/113], Loss: 2.2283 Validation Accuracy: 20.444444444444443 %\n",
      "Epoch [50/50], Step [50/113], Loss: 2.1839 Validation Accuracy: 20.77777777777778 %\n",
      "Epoch [50/50], Step [100/113], Loss: 2.2214 Validation Accuracy: 20.61111111111111 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels,dtype = torch.long)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 50 == 0:\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()),\n",
    "                  'Validation Accuracy: {} %'.format(100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d09375",
   "metadata": {},
   "source": [
    "### Model evalulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa1a0ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 5, 6,\n",
      "        6, 6, 5, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5,\n",
      "        6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 5, 6, 5, 6, 5, 5, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 5,\n",
      "        5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6,\n",
      "        6, 6, 6, 5, 6, 6, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 5, 5, 6, 6, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6, 6,\n",
      "        6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
      "        6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 5,\n",
      "        6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 6,\n",
      "        5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 5, 6, 5, 6,\n",
      "        6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 5, 5, 6, 5,\n",
      "        6, 5, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([5, 5, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 6, 5, 6, 6, 6, 5,\n",
      "        6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6,\n",
      "        5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 5, 6, 6, 5], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6, 6,\n",
      "        5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 5, 6, 5, 6, 6, 6, 5, 5, 5, 6, 6, 5, 5,\n",
      "        6, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 6, 5, 6, 5, 5, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5,\n",
      "        5, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
      "        6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6,\n",
      "        6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5, 5, 5, 5, 6, 6, 5, 5, 6, 5, 6,\n",
      "        6, 6, 6, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5, 6, 6, 5, 6, 5, 6, 6, 5, 6,\n",
      "        6, 6, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6,\n",
      "        5, 6, 6, 6, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5,\n",
      "        6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6, 5, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5, 6, 5, 6, 6, 6,\n",
      "        6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6,\n",
      "        5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 5], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5,\n",
      "        6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6,\n",
      "        6, 5, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6,\n",
      "        6, 6, 5, 5, 5, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6,\n",
      "        6, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 5, 6, 6, 6, 5, 5, 5, 6, 5, 5, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 5, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6,\n",
      "        6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6,\n",
      "        6, 5, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5,\n",
      "        6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 5, 5, 5, 6, 6, 6,\n",
      "        6, 5, 6, 5, 5, 6, 5, 6, 5, 6, 5, 6, 5, 5, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 5, 6, 5, 5, 6, 6, 5, 6, 6, 6,\n",
      "        6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6,\n",
      "        6, 5, 6, 5, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 5, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5,\n",
      "        5, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 5,\n",
      "        6, 5, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 5, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 5, 5, 6, 6, 6, 5, 6, 6,\n",
      "        6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5, 5, 6, 6, 5, 6, 6, 5, 5, 6,\n",
      "        5, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 5, 6, 6, 6], device='cuda:0')\n",
      "tensor([5, 6, 5, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5,\n",
      "        6, 6, 6, 6, 5, 5, 6, 6, 5, 5, 5, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6,\n",
      "        5, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6,\n",
      "        6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5,\n",
      "        6, 6, 5, 6, 5, 5, 5, 6, 5, 6, 5, 6, 6, 5, 5, 6, 5, 6, 6, 5, 6, 6, 6, 5,\n",
      "        6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6,\n",
      "        5, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5,\n",
      "        6, 5, 6, 6, 5, 5, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 5, 5, 6, 5, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6,\n",
      "        6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "        5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6,\n",
      "        6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 5,\n",
      "        5, 5, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6,\n",
      "        5, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6,\n",
      "        5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 5], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 6, 6, 5, 5], device='cuda:0')\n",
      "Accuracy of the network on the 1000 data: 20.444444444444443 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817/2053517580.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    print(predicted)\n",
    "\n",
    "print('Accuracy of the network on the 1000 data: {} %'.format(100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3336c9b",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a7498dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'save.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "979f082e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=10, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('save.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04096470",
   "metadata": {},
   "source": [
    "--END--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
