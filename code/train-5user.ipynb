{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68015bea",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "edd2cc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee82583",
   "metadata": {},
   "source": [
    "### Read the dataset of csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9f3240ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>France</th>\n",
       "      <th>Germany</th>\n",
       "      <th>Spain</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "      <th>CreditLevel</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15599054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.801215</td>\n",
       "      <td>0.198785</td>\n",
       "      <td>0.740364</td>\n",
       "      <td>0.464691</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.435955</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15775433</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.211294</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.561170</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15660125</td>\n",
       "      <td>0.239005</td>\n",
       "      <td>0.760995</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.671702</td>\n",
       "      <td>0.562711</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.170473</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15784304</td>\n",
       "      <td>0.369095</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.630905</td>\n",
       "      <td>0.536910</td>\n",
       "      <td>0.352936</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.434634</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15642311</td>\n",
       "      <td>0.160870</td>\n",
       "      <td>0.839130</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.548261</td>\n",
       "      <td>0.356035</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.695248</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2527</th>\n",
       "      <td>15630106</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.276947</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>15633757</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.164313</td>\n",
       "      <td>0.557549</td>\n",
       "      <td>0.196406</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.502076</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2529</th>\n",
       "      <td>15798254</td>\n",
       "      <td>0.514966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.485034</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.180963</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.814625</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2530</th>\n",
       "      <td>15690297</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.688253</td>\n",
       "      <td>0.517317</td>\n",
       "      <td>0.215696</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.455584</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2531</th>\n",
       "      <td>15602414</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516858</td>\n",
       "      <td>0.407405</td>\n",
       "      <td>0.255428</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.607929</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2532 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CustomerId    France   Germany     Spain    Tenure   Balance  \\\n",
       "0       15599054  0.000000  0.801215  0.198785  0.740364  0.464691   \n",
       "1       15775433  0.000000  1.000000  0.000000  0.100000  0.211294   \n",
       "2       15660125  0.239005  0.760995  0.000000  0.671702  0.562711   \n",
       "3       15784304  0.369095  0.000000  0.630905  0.536910  0.352936   \n",
       "4       15642311  0.160870  0.839130  0.000000  0.548261  0.356035   \n",
       "...          ...       ...       ...       ...       ...       ...   \n",
       "2527    15630106  0.000000  0.000000  1.000000  0.200000  0.000000   \n",
       "2528    15633757  1.000000  0.000000  0.000000  0.164313  0.557549   \n",
       "2529    15798254  0.514966  0.000000  0.485034  0.600000  0.180963   \n",
       "2530    15690297  0.000000  1.000000  0.000000  0.688253  0.517317   \n",
       "2531    15602414  0.000000  1.000000  0.000000  0.516858  0.407405   \n",
       "\n",
       "      NumOfProducts  HasCrCard  IsActiveMember  EstimatedSalary  Exited  \\\n",
       "0          0.000000          0               1         0.435955       0   \n",
       "1          0.333333          1               1         0.561170       0   \n",
       "2          0.333333          1               1         0.170473       0   \n",
       "3          0.000000          1               1         0.434634       0   \n",
       "4          0.333333          0               0         0.695248       0   \n",
       "...             ...        ...             ...              ...     ...   \n",
       "2527       0.333333          1               0         0.276947       0   \n",
       "2528       0.196406          1               1         0.502076       0   \n",
       "2529       0.000000          1               0         0.814625       1   \n",
       "2530       0.215696          1               0         0.455584       1   \n",
       "2531       0.255428          1               1         0.607929       0   \n",
       "\n",
       "      CreditLevel  \n",
       "0               3  \n",
       "1               6  \n",
       "2               2  \n",
       "3               3  \n",
       "4               8  \n",
       "...           ...  \n",
       "2527            3  \n",
       "2528            8  \n",
       "2529            0  \n",
       "2530            1  \n",
       "2531            9  \n",
       "\n",
       "[2532 rows x 12 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.read_csv('BankChurners_fd5.csv')\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bc30b9",
   "metadata": {},
   "source": [
    "#### Split the data into train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c12f6e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Change the train  file path for different users data\n",
    "train = pd.read_csv('BankChurners_fdtrain.csv')\n",
    "test = pd.read_csv('BankChurners_fdtest.csv')\n",
    "\n",
    "train_y = pd.DataFrame(train['CreditLevel'])\n",
    "train_X = train.drop(columns=['CreditLevel'])\n",
    "train_X = train_X.drop(columns=['CustomerId'])\n",
    "\n",
    "test_y = pd.DataFrame(test['CreditLevel'])\n",
    "test_X = test.drop(columns=['CreditLevel'])\n",
    "test_X = test_X.drop(columns=['CustomerId'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f186774f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = torch.utils.data.TensorDataset(torch.Tensor(np.array(train_X)), torch.squeeze(torch.Tensor(np.array(train_y))))\n",
    "test_set = torch.utils.data.TensorDataset(torch.Tensor(np.array(test_X)), torch.squeeze(torch.Tensor(np.array(test_y))))\n",
    "            \n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_set, \n",
    "                                           batch_size=32, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_set, \n",
    "                                          batch_size=32, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caafea11",
   "metadata": {},
   "source": [
    "### Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "dd040ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NN, self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(10, 64)\n",
    "        self.fc2 = nn.Linear(64, 16)\n",
    "        self.fc3 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.fc1(x),negative_slope=0.01)\n",
    "        x = F.leaky_relu(self.fc2(x),negative_slope=0.01)\n",
    "        x = F.softmax(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26da7e4c",
   "metadata": {},
   "source": [
    "#### Loss function and learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b904930",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = NN().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f402ecb",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "651f26dd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1119/3075316110.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels,dtype = torch.long)\n",
      "/tmp/ipykernel_1119/2053517580.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/50], Step [50/80], Loss: 2.2992 Validation Accuracy: 15.679304897314376 %\n",
      "Epoch [2/50], Step [50/80], Loss: 2.2841 Validation Accuracy: 14.454976303317535 %\n",
      "Epoch [3/50], Step [50/80], Loss: 2.2343 Validation Accuracy: 20.85308056872038 %\n",
      "Epoch [4/50], Step [50/80], Loss: 2.2143 Validation Accuracy: 20.89257503949447 %\n",
      "Epoch [5/50], Step [50/80], Loss: 2.2447 Validation Accuracy: 21.12954186413902 %\n",
      "Epoch [6/50], Step [50/80], Loss: 2.2523 Validation Accuracy: 21.011058451816744 %\n",
      "Epoch [7/50], Step [50/80], Loss: 2.2778 Validation Accuracy: 22.748815165876778 %\n",
      "Epoch [8/50], Step [50/80], Loss: 2.2065 Validation Accuracy: 23.143759873617693 %\n",
      "Epoch [9/50], Step [50/80], Loss: 2.1728 Validation Accuracy: 22.82780410742496 %\n",
      "Epoch [10/50], Step [50/80], Loss: 2.2472 Validation Accuracy: 22.86729857819905 %\n",
      "Epoch [11/50], Step [50/80], Loss: 2.2005 Validation Accuracy: 22.669826224328595 %\n",
      "Epoch [12/50], Step [50/80], Loss: 2.1726 Validation Accuracy: 23.30173775671406 %\n",
      "Epoch [13/50], Step [50/80], Loss: 2.1545 Validation Accuracy: 23.104265402843602 %\n",
      "Epoch [14/50], Step [50/80], Loss: 2.2082 Validation Accuracy: 23.499210110584517 %\n",
      "Epoch [15/50], Step [50/80], Loss: 2.1958 Validation Accuracy: 23.617693522906794 %\n",
      "Epoch [16/50], Step [50/80], Loss: 2.1783 Validation Accuracy: 23.77567140600316 %\n",
      "Epoch [17/50], Step [50/80], Loss: 2.1805 Validation Accuracy: 22.709320695102686 %\n",
      "Epoch [18/50], Step [50/80], Loss: 2.1499 Validation Accuracy: 23.657187993680886 %\n",
      "Epoch [19/50], Step [50/80], Loss: 2.1832 Validation Accuracy: 23.81516587677725 %\n",
      "Epoch [20/50], Step [50/80], Loss: 2.1378 Validation Accuracy: 23.933649289099527 %\n",
      "Epoch [21/50], Step [50/80], Loss: 2.2316 Validation Accuracy: 23.578199052132703 %\n",
      "Epoch [22/50], Step [50/80], Loss: 2.1964 Validation Accuracy: 23.578199052132703 %\n",
      "Epoch [23/50], Step [50/80], Loss: 2.2010 Validation Accuracy: 23.578199052132703 %\n",
      "Epoch [24/50], Step [50/80], Loss: 2.2091 Validation Accuracy: 22.669826224328595 %\n",
      "Epoch [25/50], Step [50/80], Loss: 2.1691 Validation Accuracy: 23.657187993680886 %\n",
      "Epoch [26/50], Step [50/80], Loss: 2.2004 Validation Accuracy: 22.906793048973142 %\n",
      "Epoch [27/50], Step [50/80], Loss: 2.1800 Validation Accuracy: 23.380726698262244 %\n",
      "Epoch [28/50], Step [50/80], Loss: 2.1104 Validation Accuracy: 24.447077409162716 %\n",
      "Epoch [29/50], Step [50/80], Loss: 2.1979 Validation Accuracy: 23.53870458135861 %\n",
      "Epoch [30/50], Step [50/80], Loss: 2.1654 Validation Accuracy: 23.02527646129542 %\n",
      "Epoch [31/50], Step [50/80], Loss: 2.1746 Validation Accuracy: 23.81516587677725 %\n",
      "Epoch [32/50], Step [50/80], Loss: 2.2303 Validation Accuracy: 24.21011058451817 %\n",
      "Epoch [33/50], Step [50/80], Loss: 2.1204 Validation Accuracy: 23.341232227488153 %\n",
      "Epoch [34/50], Step [50/80], Loss: 2.1815 Validation Accuracy: 23.736176935229068 %\n",
      "Epoch [35/50], Step [50/80], Loss: 2.2423 Validation Accuracy: 23.578199052132703 %\n",
      "Epoch [36/50], Step [50/80], Loss: 2.1914 Validation Accuracy: 23.222748815165875 %\n",
      "Epoch [37/50], Step [50/80], Loss: 2.1712 Validation Accuracy: 23.499210110584517 %\n",
      "Epoch [38/50], Step [50/80], Loss: 2.1331 Validation Accuracy: 23.459715639810426 %\n",
      "Epoch [39/50], Step [50/80], Loss: 2.2386 Validation Accuracy: 23.617693522906794 %\n",
      "Epoch [40/50], Step [50/80], Loss: 2.1186 Validation Accuracy: 23.97314375987362 %\n",
      "Epoch [41/50], Step [50/80], Loss: 2.2389 Validation Accuracy: 23.143759873617693 %\n",
      "Epoch [42/50], Step [50/80], Loss: 2.1576 Validation Accuracy: 22.906793048973142 %\n",
      "Epoch [43/50], Step [50/80], Loss: 2.1741 Validation Accuracy: 23.30173775671406 %\n",
      "Epoch [44/50], Step [50/80], Loss: 2.2320 Validation Accuracy: 23.81516587677725 %\n",
      "Epoch [45/50], Step [50/80], Loss: 2.2164 Validation Accuracy: 23.81516587677725 %\n",
      "Epoch [46/50], Step [50/80], Loss: 2.1781 Validation Accuracy: 23.617693522906794 %\n",
      "Epoch [47/50], Step [50/80], Loss: 2.0385 Validation Accuracy: 23.696682464454977 %\n",
      "Epoch [48/50], Step [50/80], Loss: 2.1735 Validation Accuracy: 23.380726698262244 %\n",
      "Epoch [49/50], Step [50/80], Loss: 2.2034 Validation Accuracy: 23.85466034755134 %\n",
      "Epoch [50/50], Step [50/80], Loss: 2.1757 Validation Accuracy: 23.499210110584517 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "num_epochs = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (inputs, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        inputs = inputs.to(device)\n",
    "        labels = torch.tensor(labels,dtype = torch.long)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 50 == 0:\n",
    "            model.eval()\n",
    "            correct = 0\n",
    "            total = 0\n",
    "            for inputs, labels in test_loader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                .format(epoch+1, num_epochs, i+1, total_step, loss.item()),\n",
    "                  'Validation Accuracy: {} %'.format(100 * correct / total))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8482e12f",
   "metadata": {},
   "source": [
    "### Model evalulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81c78f6a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 5, 6,\n",
      "        6, 6, 5, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5,\n",
      "        6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 5, 6, 5, 6, 5, 5, 6, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 5,\n",
      "        5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6,\n",
      "        6, 6, 6, 5, 6, 6, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 5, 5, 6, 6, 5, 5, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6, 6,\n",
      "        6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
      "        6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 5,\n",
      "        6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 6,\n",
      "        5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 5, 6, 5, 6,\n",
      "        6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 5, 5, 6, 6, 5, 5, 5, 6, 5,\n",
      "        6, 5, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([5, 5, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 6, 5, 6, 6, 6, 5,\n",
      "        6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6,\n",
      "        5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 5, 6, 6, 5], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6, 6, 5, 6, 5, 6, 6,\n",
      "        5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 5, 6, 5, 6, 6, 6, 5, 5, 5, 6, 6, 5, 5,\n",
      "        6, 5, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 6, 5, 6, 5, 5, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5,\n",
      "        5, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5,\n",
      "        6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6,\n",
      "        6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5, 5, 5, 5, 6, 6, 5, 5, 6, 5, 6,\n",
      "        6, 6, 6, 5, 5, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 5, 5, 5, 6, 5, 6, 6, 5, 6, 5, 6, 6, 5, 6,\n",
      "        6, 6, 6, 6, 6, 5, 5, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6,\n",
      "        5, 6, 6, 6, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5,\n",
      "        6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6, 5, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5, 6, 5, 6, 6, 6,\n",
      "        6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 5, 5, 5, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6,\n",
      "        5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 5], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5,\n",
      "        6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6,\n",
      "        6, 5, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6,\n",
      "        6, 6, 5, 5, 5, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([5, 6, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6,\n",
      "        6, 5, 6, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 5, 6, 6, 6, 5, 5, 5, 6, 5, 5, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 5, 6, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6,\n",
      "        6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6,\n",
      "        6, 5, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5,\n",
      "        6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 5, 5, 5, 6, 5, 5, 5, 6, 6, 6,\n",
      "        6, 5, 6, 5, 5, 6, 5, 6, 5, 6, 5, 6, 5, 5, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 5, 5, 6, 5, 5, 6, 6, 5, 6, 6, 6,\n",
      "        6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6,\n",
      "        6, 5, 6, 5, 5, 6, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([5, 6, 6, 5, 6, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 5,\n",
      "        5, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 5,\n",
      "        6, 5, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6], device='cuda:0')\n",
      "tensor([6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 5, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 5, 5, 6, 6, 6, 5, 6, 6,\n",
      "        6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 5, 5, 6, 6, 5, 6, 6, 5, 5, 6,\n",
      "        5, 5, 6, 5, 6, 6, 6, 5, 6, 5, 5, 6, 5, 6, 6, 6], device='cuda:0')\n",
      "tensor([5, 6, 5, 6, 5, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 5,\n",
      "        6, 6, 6, 6, 5, 5, 6, 6, 5, 5, 5, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6, 5, 6,\n",
      "        6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6,\n",
      "        5, 6, 5, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6,\n",
      "        6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5,\n",
      "        6, 6, 5, 6, 5, 5, 5, 6, 5, 6, 5, 6, 6, 5, 5, 6, 5, 6, 6, 5, 6, 6, 6, 5,\n",
      "        6, 6, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 5, 6, 6, 6, 5, 6, 6, 6,\n",
      "        5, 5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 5, 6, 6, 6, 5, 6, 5, 6, 5, 6, 6, 6, 5,\n",
      "        6, 5, 6, 6, 5, 5, 6, 5, 6, 5, 6, 5, 6, 6, 5, 6], device='cuda:0')\n",
      "tensor([6, 6, 6, 5, 5, 5, 6, 5, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 6, 6, 6, 6,\n",
      "        6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6, 5, 5, 5, 6, 6, 6, 6, 6, 6,\n",
      "        5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 5, 6, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([6, 5, 5, 6, 6, 6, 6, 6, 6, 5, 5, 6, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 5, 6,\n",
      "        6, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 6, 6, 6, 5, 5, 5, 5, 6, 5, 6, 5, 6, 5,\n",
      "        5, 5, 6, 6, 6, 6, 5, 6, 5, 6, 6, 6, 6, 6, 6, 5], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 5, 6, 6, 6, 6, 6, 5, 6, 6, 6, 6,\n",
      "        5, 5, 5, 6, 6, 6, 5, 6, 6, 6, 5, 6, 6, 5, 6, 6, 6, 6, 6, 5, 6, 6, 5, 6,\n",
      "        5, 6, 6, 6, 5, 6, 6, 6, 6, 5, 6, 6, 5, 6, 6, 5], device='cuda:0')\n",
      "tensor([5, 6, 6, 6, 6, 6, 5, 5], device='cuda:0')\n",
      "Accuracy of the network on the 1000 data: 20.444444444444443 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_817/2053517580.py:12: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  x = F.softmax(self.fc3(x))\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = images.to(device)\n",
    "    labels = labels.to(device)\n",
    "    outputs = model(images)\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)\n",
    "    correct += (predicted == labels).sum().item()\n",
    "    print(predicted)\n",
    "\n",
    "print('Accuracy of the network on the 1000 data: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "755faa5d",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4c90d741",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'save.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6048402e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NN(\n",
       "  (fc1): Linear(in_features=10, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=16, bias=True)\n",
       "  (fc3): Linear(in_features=16, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.load('save.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79cdb4a1",
   "metadata": {},
   "source": [
    "--END--"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
